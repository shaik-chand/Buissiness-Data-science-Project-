# -*- coding: utf-8 -*-
"""Untitled27.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jOMQAWfhE6o4NRbnEGLwDWzMXTNhqLbW
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

'''import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))''''

insurance_data=pd.read_csv('/content/insurance_data.csv')
employee_data=pd.read_csv('/content/employee_data.csv')
vendor_data=pd.read_csv('/content/vendor_data.csv')
display('insurence.head()', 'employee.head()', 'vendor.head()')

insurance_data.head()

insurance_data.shape

vendor_data.head()

vendor_data.shape

employee_data.head()

employee_data.tail()

employee_data.shape

"""#Task 1"""

#merging
m1=pd.merge(insurance_data,employee_data,on='AGENT_ID',how='left',suffixes=('_CUSTOMER','_AGENT'))
view=pd.merge(m1,vendor_data,on='VENDOR_ID',how='left')
view

"""#Task 2
Top 3 insurence type

"""

insurance_data.INSURANCE_TYPE.value_counts()[:3]

"""#Task 3
Top 5 States
"""

insurance_data.columns

insurance_data[insurance_data['RISK_SEGMENTATION']=='H'].STATE.value_counts()[:5]

"""#Task 4

"""

view.columns

"""The columns above in view with no suffixes represent column of vendor data.

"""

view['COLOCATION'] = (view['STATE_CUSTOMER']==view['INCIDENT_STATE'])&(view['INCIDENT_STATE']==view['STATE_AGENT'])
# changing column vaues from True to 1 and False to 0
view['COLOCATION']=view.COLOCATION.astype('int')

view.COLOCATION.mean()

"""#Task 5
Data entry error was detected in the data and you are required to correct it. If for any
claim transaction “AUTHORITY_CONTACTED” is NOT “Police” and POLICE_AVAILABLE == 1
Then Update “AUTHORITY_CONTACTED” to Police.
"""

non_police = view[view['AUTHORITY_CONTACTED']!='Police']
update_rows = non_police[non_police['POLICE_REPORT_AVAILABLE']==1].index
# Updating the Authority column
view.loc[update_rows,'AUTHORITY_CONTACTED'] = 'Police'
# Checking
view[(view['POLICE_REPORT_AVAILABLE']==1)&(view['AUTHORITY_CONTACTED']!='Police')]

"""# Task 6
Business wants to check the Claim Amount for deviation for each transaction, they would
like you to calculate as follow
CLAIM_DEVIATION = AVG_CLAIM_AMOUNT_FOR_LAST_30DAYS (same insurance type)
/ CURRENT_CLAIM_AMOUNT
If the value < 0.5 THEN CLAIM_DEVIATION = 1 ELSE 0
If there is less than 30 days of transaction history THEN
-1 Note: LAST_30DAYS does not include current day
"""

view.TXN_DATE_TIME.max()

#ASSUME
curr_date = pd.to_datetime('2021-06-30')
view['TXN_DATE_TIME'] = pd.to_datetime(view['TXN_DATE_TIME'])
last_30 = view.loc[(view['TXN_DATE_TIME'] > '2021-05-30') & (view['TXN_DATE_TIME'] < '2021-06-30')]

# Getting average claim of last 30 days insurance type wise and storing it in dictionary
average_claim = last_30.groupby('INSURANCE_TYPE').mean()['CLAIM_AMOUNT'].to_dict()

def Claim_deviation(row):
    if (curr_date - row['TXN_DATE_TIME'])<pd.Timedelta(days=30):
        return -1
    claim_deviation = average_claim[row['INSURANCE_TYPE']] / row['CLAIM_AMOUNT']
    if claim_deviation < 0.5:
        return 1
    else:
        return 0

view['CLAIM_DEVIATION'] = view.apply(Claim_deviation,axis=1)

view.CLAIM_DEVIATION.value_counts()



"""#Task 7
Find All Agents who have worked on more than 2 types of Insurance Claims. Sort them by
Total Claim Amount Approved under them in descending order
"""

# calculating insurance types worked on of each agent
type_count = view.groupby('AGENT_ID')['INSURANCE_TYPE'].nunique()

# Calculating wheather agent has more than 2 insurance types
agent_insurance_types = type_count>2

# getting list of agents who have worked on more than 2 types of insurance types
multi_type_agents = agent_insurance_types[agent_insurance_types].index

Top_agents = view.groupby(['AGENT_ID','AGENT_NAME']).sum().loc[multi_type_agents][['CLAIM_AMOUNT']].sort_values('CLAIM_AMOUNT',ascending=False)
Top_agents

Top_agents.join(type_count)

"""#Task 8
Mobile & Travel Insurance premium are discounted by 10%
Health and Property Insurance premium are increased by 7%
Life and Motor Insurance premium are marginally increased by 2%
What will be overall change in % of the Premium Amount Collected for all these Customer?
"""

premium_collected_earlier = view['PREMIUM_AMOUNT'].sum()

# total premium collected by each insurance type
prem_by_types = view.groupby('INSURANCE_TYPE').sum()['PREMIUM_AMOUNT'].to_dict()
prem_by_types

# Mobile & Travel premium discounted by 10%
prem_by_types['Mobile']*=0.9
prem_by_types['Travel']*=0.9
# Health and Property premium increases by 7%
prem_by_types['Health']*=1.07
prem_by_types['Property']*=1.07
# Life and Motor premium increased by 2%
prem_by_types['Life']*=1.02
prem_by_types['Motor']*=1.02

# premium after discount and increase
revised_premium = sum(prem_by_types.values())

(revised_premium-premium_collected_earlier)*100/premium_collected_earlier

premium_collected_earlier,revised_premium

premium_collected_earlier,revised_premium

"""#Task 9"""

# calculating status for discount with given conditions
disc_status=(view['TENURE']>60)&(view['EMPLOYMENT_STATUS']=='N')&(view['NO_OF_FAMILY_MEMBERS']>=4)
# Creating an column ELIGIBLE_FOR_DISCOUNT with above values
view['ELIGIBLE_FOR_DISCOUNT'] = disc_status.astype('int')

# Mean of this column
view.ELIGIBLE_FOR_DISCOUNT.mean()

"""#Task 10
Business wants to check Claim Velocity which is defined as follow
CLAIM_VELOCITY = NO_OF_CLAIMS_IN_LAST30DAYS (for the current insurance type)
/ NO_OF_CLAIMS_IN_LAST3DAYS (for the current insurance type)
Note: LAST30DAYS & LAST3DAYS does not include current
data
"""

curr_date

view['CLAIM_STATUS'].value_counts()

last_3_days = view.loc[(view['TXN_DATE_TIME'] > curr_date-pd.Timedelta(days=4)) & (view['TXN_DATE_TIME'] < curr_date)]

# Calculating total approved claims insurance type wise in last 30 days
claims_in_last_30_days = pd.DataFrame.from_dict(last_30[last_30['CLAIM_STATUS']=='A'].groupby('INSURANCE_TYPE').size().to_dict(),orient='index',columns=['NO_OF_CLAIMS_IN_LAST30DAYS'])
# Calculating total approved claims insurance type wise in last 3 days
claims_in_last_3_days = pd.DataFrame.from_dict(last_3_days[last_3_days['CLAIM_STATUS']=='A'].groupby('INSURANCE_TYPE').size().to_dict(),orient='index',columns=['NO_OF_CLAIMS_IN_LAST3DAYS'])

approved_claims = claims_in_last_30_days.join(claims_in_last_3_days)
approved_claims['CLAIM_VELOCITY'] = approved_claims['NO_OF_CLAIMS_IN_LAST30DAYS']/approved_claims['NO_OF_CLAIMS_IN_LAST3DAYS']
approved_claims

All_claims30D = pd.DataFrame.from_dict(last_30.groupby('INSURANCE_TYPE').size().to_dict(),orient='index',columns=['NO_OF_CLAIMS_IN_LAST30DAYS'])
All_claims3D = pd.DataFrame.from_dict(last_3_days.groupby('INSURANCE_TYPE').size().to_dict(),orient='index',columns=['NO_OF_CLAIMS_IN_LAST3DAYS'])
total_claims=All_claims30D.join(All_claims3D)
total_claims['CLAIM_VELOCITY'] = total_claims['NO_OF_CLAIMS_IN_LAST30DAYS']/total_claims['NO_OF_CLAIMS_IN_LAST3DAYS']
total_claims

"""#Task11
Find all low performing agents i.e. employees who are in the bottom 5 percentile based
on Claims worked by them.
"""

bottom_5percentile_limit = view.groupby('AGENT_ID').sum().quantile(0.05)['CLAIM_AMOUNT']
Agent_grouped_data = view.groupby('AGENT_ID').sum()
# Low performing agent data
low_performing_agents = Agent_grouped_data[Agent_grouped_data['CLAIM_AMOUNT']<=bottom_5percentile_limit][['CLAIM_AMOUNT']]
low_performing_agents

"""#Task 12
Business wants to find all Suspicious Employees (Agents).
IF TOTAL CLAIM AMOUNT which meet below criteria is >= 15000 THEN AGENT is classified
as Suspicious ELSE Not
CLAIM_STATUS = Approved AND CUSTOMER_RISK_SEGMENTATION = High
AND INCIDENT_SEVERITY = “Major Loss”
If Suspicious, then 1 ELSE 0. Find mean of this column.
"""

criteria = (view['CLAIM_STATUS']=='A')&(view['RISK_SEGMENTATION']=='H')&(view['INCIDENT_SEVERITY']=='Major Loss')
# transactions that follow criteria
criteriamet = view[criteria]
grouped_suspicion_data = criteriamet.groupby('AGENT_ID').sum()
# storing agents_id that are suspicious(met all the criteria)
suspicious_agents = list(grouped_suspicion_data[grouped_suspicion_data['CLAIM_AMOUNT']>=15000].index)

employee_data

employee_data['SUSPICIOUS'] = 0
sus_emp_slice = employee_data['AGENT_ID'].isin(suspicious_agents)
# Changing suspicious column value to 1 of suspicious employees
employee_data.loc[sus_emp_slice,'SUSPICIOUS']=1
employee_data['SUSPICIOUS'].mean()

